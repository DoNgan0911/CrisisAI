# -*- coding: utf-8 -*-
"""enrich_sa_locations_short.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LLPgxjMh0d8eAlyOgKgFahfcJcmoLoOx
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df = pd.read_csv('SA_no_location_tweets.csv')

# Convert created_at to datetime
df["created_at"] = pd.to_datetime(df["created_at"], errors="coerce")

# Group by date
counts = df.groupby(df["created_at"].dt.date).size()

# Plot
plt.figure(figsize=(12,6))
counts.plot(kind="bar")
plt.title("Distribution of SA_no_location_tweets over time")
plt.xlabel("Date")
plt.ylabel("Tweet count")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

SA_no_locations.head(1)







"""
Short version: enrich SA tweets with spatial details only.
- Assumes `location_names` is always []
- Uses fire-name hints in text (Camp/Woolsey/Hill/Nurse)
- Optional: call Llama 3.1â€‘8B Instruct for a JSON guess; else rule-based fallback
- Outputs minimal spatial fields + provenance

Run:
  python enrich_sa_locations_short.py \
    --in_csv SA_no_location_tweets.csv \
    --out_csv SA_no_location_tweets_enriched.csv \
    [--use_llm] [--model_id meta-llama/Meta-Llama-3.1-8B-Instruct] [--device auto]
"""
from __future__ import annotations
import re, json, math, random, argparse
from typing import List, Dict, Any, Optional
import pandas as pd

# ---------------- Hotspots & pools ----------------
HOTSPOTS = [
    {"name":"Butte","type":"county","fire":"Camp","lat":39.6519,"lon":-121.59},
    {"name":"Paradise","type":"city","fire":"Camp","lat":39.7596,"lon":-121.6219},
    {"name":"Chico","type":"city","fire":"Camp","lat":39.7285,"lon":-121.8375},
    {"name":"Magalia","type":"city","fire":"Camp","lat":39.8121,"lon":-121.5783},
    {"name":"Enloe Medical Center (Chico)","type":"facility","fire":"Camp","lat":39.7424,"lon":-121.8502},
    {"name":"Silver Dollar Fairgrounds (Chico)","type":"facility","fire":"Camp","lat":39.7174,"lon":-121.8114},
    {"name":"Los Angeles","type":"county","fire":"Woolsey","lat":34.3155,"lon":-118.2097},
    {"name":"Ventura","type":"county","fire":"Woolsey","lat":34.4458,"lon":-119.0780},
    {"name":"Malibu","type":"city","fire":"Woolsey","lat":34.0356,"lon":-118.6894},
    {"name":"Agoura Hills","type":"city","fire":"Woolsey","lat":34.1482,"lon":-118.7655},
    {"name":"Thousand Oaks","type":"city","fire":"Woolsey","lat":34.1706,"lon":-118.8376},
    {"name":"Camarillo","type":"city","fire":"Hill","lat":34.2176,"lon":-119.0384},
    {"name":"Pepperdine University (Malibu)","type":"facility","fire":"Woolsey","lat":34.0430,"lon":-118.7093},
    {"name":"Solano","type":"county","fire":"Nurse","lat":38.2219,"lon":-121.9164},
    {"name":"Vacaville","type":"city","fire":"Nurse","lat":38.3566,"lon":-121.9877},
]
ALL = HOTSPOTS
NOCAL = [h for h in HOTSPOTS if h["fire"] in {"Camp","Nurse"}]
SOCAL = [h for h in HOTSPOTS if h["fire"] in {"Woolsey","Hill"}]
NAME2HS = {h["name"].lower(): h for h in HOTSPOTS}

# ------------- Fire & region hints from text -------------
FIRE_PAT = {
    "Camp":    re.compile(r"\b#?camp\s*fire\b|#?campfire\b|\bcamp\b.*\bblaze\b", re.I),
    "Woolsey": re.compile(r"\b#?woolsey\s*fire\b|#?woolseyfire\b|\bwoolsey\b.*\bblaze\b", re.I),
    "Hill":    re.compile(r"\b#?hill\s*fire\b|#?hillfire\b|\bhill\b.*\bblaze\b", re.I),
    "Nurse":   re.compile(r"\b#?nurse\s*fire\b|#?nursefire\b|\bnurse\b.*\bblaze\b", re.I),
}
REGION_SOCAL = re.compile(r"southern california|los angeles|ventura|malibu|agoura|thousand oaks", re.I)
REGION_NOCAL = re.compile(r"northern california|butte|paradise|chico|magalia|solano|vacaville", re.I)

def fire_hint(text: str) -> Optional[str]:
    for name, pat in FIRE_PAT.items():
        if pat.search(text or ""):
            return name
    return None

def region_pool(text: str):
    if REGION_NOCAL.search(text or ""):
        return NOCAL, "region:norcal"
    if REGION_SOCAL.search(text or ""):
        return SOCAL, "region:socal"
    return ALL, "fallback:all"

# --------------------- Minimal LLM wrapper ---------------------
USE_TRANSFORMERS = True
try:
    from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline
except Exception:
    USE_TRANSFORMERS = False

class Llama:
    def __init__(self, model_id: str, device: str = "auto"):
        if not USE_TRANSFORMERS:
            raise RuntimeError("transformers not installed")
        tok = AutoTokenizer.from_pretrained(model_id, use_fast=True)
        mdl = AutoModelForCausalLM.from_pretrained(model_id, device_map=device, torch_dtype="auto")
        self.pipe = pipeline("text-generation", model=mdl, tokenizer=tok, return_full_text=False)

    def guess(self, text: str, pool_names: List[str]) -> Optional[Dict[str, Any]]:
        guide = ", ".join(sorted(set(pool_names)))
        prompt = (
            "Return ONLY one JSON object for spatial enrichment of a 2018 CA wildfire tweet.\n"
            f"Prefer places from: {guide}.\n"
            f"Tweet: {text}\n"
            f"SCHEMA keys: city, county, region, lat, lon, confidence, rationale"
        )
        out = self.pipe(prompt, max_new_tokens=256, temperature=0.3, top_p=0.9)[0]["generated_text"].strip()
        m = re.search(r"\{[\s\S]*\}$", out)
        js = m.group(0) if m else out
        try:
            d = json.loads(js)
            return d if isinstance(d, dict) else None
        except Exception:
            return None

# ---------------------- Utility helpers ----------------------

def jitter(lat: float, lon: float, km: float = 2.0):
    if lat is None or lon is None or km <= 0: return lat, lon
    R = 6371.0
    b = random.uniform(0, 2*math.pi)
    d = random.uniform(0, km)
    lat1, lon1 = math.radians(lat), math.radians(lon)
    ang = d / R
    lat2 = math.asin(math.sin(lat1)*math.cos(ang) + math.cos(lat1)*math.sin(ang)*math.cos(b))
    lon2 = lon1 + math.atan2(math.sin(b)*math.sin(ang)*math.cos(lat1), math.cos(ang)-math.sin(lat1)*math.sin(lat2))
    lon2 = ((math.degrees(lon2)+540)%360)-180
    return math.degrees(lat2), lon2

# --------------------------- Core ----------------------------

def choose_pool(text: str):
    f = fire_hint(text)
    if f:
        pool = [h for h in HOTSPOTS if h["fire"] == f]
        return pool, f"fire:{f}"
    return region_pool(text)


def resolve_row(row: pd.Series, llama: Optional[Llama], jitter_km: float = 2.0):
    text = str(row.get("text", ""))
    pool, reason = choose_pool(text)

    # Try LLM first (optional)
    if llama is not None:
        guess = llama.guess(text, [h["name"] for h in pool])
        if guess:
            city = str(guess.get("city",""))
            county = str(guess.get("county",""))
            name = (city or county).lower()
            h = NAME2HS.get(name, random.choice(pool))
            lat, lon = jitter(h["lat"], h["lon"], jitter_km)
            return {
                "place": h["name"], "place_type": h["type"], "lat": lat, "lon": lon, "fire": h["fire"],
                "decision": ("pool_by_fire" if reason.startswith("fire:") else reason),
                "decision_detail": reason.split(":",1)[-1],
                "pool_group": ("norcal" if h["fire"] in {"Camp","Nurse"} else "socal"),
                "enr_city": city, "enr_county": county,
                "enr_region": str(guess.get("region","")),
                "enr_lat": guess.get("lat"), "enr_lon": guess.get("lon"),
                "enr_confidence": guess.get("confidence", 0.0),
                "enr_rationale": guess.get("rationale",""),
                "enr_source": "llama-3.1-8b-instruct",
            }

    # Rule-only fallback
    h = random.choice(pool)
    lat, lon = jitter(h["lat"], h["lon"], jitter_km)
    return {
        "place": h["name"], "place_type": h["type"], "lat": lat, "lon": lon, "fire": h["fire"],
        "decision": ("pool_by_fire" if reason.startswith("fire:") else reason),
        "decision_detail": reason.split(":",1)[-1],
        "pool_group": ("norcal" if h["fire"] in {"Camp","Nurse"} else "socal"),
    }

# --------------------------- CLI ----------------------------

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--in_csv", required=True)
    ap.add_argument("--out_csv", required=True)
    ap.add_argument("--use_llm", action="store_true")
    ap.add_argument("--model_id", default="meta-llama/Meta-Llama-3.1-8B-Instruct")
    ap.add_argument("--device", default="auto")
    ap.add_argument("--jitter_km", type=float, default=2.0)
    args = ap.parse_args()

    df = pd.read_csv(args.in_csv)
    llama = Llama(args.model_id, args.device) if args.use_llm else None

    out = [ {**{k: row.get(k) for k in df.columns}, **resolve_row(row, llama, args.jitter_km)}
            for _, row in df.iterrows() ]
    pd.DataFrame(out).to_csv(args.out_csv, index=False)
    print(f"Saved -> {args.out_csv}")

if __name__ == "__main__":
    main()